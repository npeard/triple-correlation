model:
  type: "GPT"
  n_layer: 1
  n_head: 4
  n_embd: 128
  dropout: 0.1
  bias: false

training:
  max_epochs: 50
  batch_size: 512
  optimizer: "Adam"
  learning_rate: 3e-4
  weight_decay: 0.1
  accelerator: "cpu"
  devices: "0"
  use_logging: false
  wandb_project: "triple_correlation"
  experiment_name: "gpt_biphase"
  checkpoint_dir: "./checkpoints"
  random_seed: 42

data:
  data_dir: "./biphase_gpt/data"
  train_file: "train.h5"
  val_file: "val.h5"
  test_file: "test.h5"
  num_workers: 4
  dataset_params:
    train_samples: 1000
    val_samples: 100
    test_samples: 100
    num_pix: 21
