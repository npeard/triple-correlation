{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "%load_ext autotime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from fluo.speckle1d import Fluorescence1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = int(1e4)\n",
    "num_pix = 101\n",
    "Phi_dim = ((num_pix//2 + 1)//2 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomizing Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nGenerating {num_samples} samples...\")\n",
    "Phi_samples = np.zeros((num_samples, Phi_dim, Phi_dim))\n",
    "phase_samples = np.zeros((num_samples, num_pix))\n",
    "for i in tqdm(range(num_samples)):\n",
    "    # Generate random phase\n",
    "    phase = np.random.uniform(-np.pi, np.pi, num_pix // 2)\n",
    "    phase = np.concatenate((-phase, np.zeros(1), np.flip(phase)))\n",
    "    phase_samples[i, :] = phase\n",
    "    \n",
    "    # Compute Phi matrix\n",
    "    Phi = Fluorescence1D.compute_Phi_from_phase(phase[num_pix // 2:])    \n",
    "    Phi_samples[i, :, :] = Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean\", np.mean(Phi_samples))\n",
    "print(\"StdDev\", np.std(Phi_samples))\n",
    "print(\"RMS\", np.mean(4*Phi_samples**2))\n",
    "\n",
    "print(\"Mean\", np.mean(phase_samples))\n",
    "print(\"StdDev\", np.std(phase_samples))\n",
    "print(\"RMS\", np.mean(4*phase_samples**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite fast, maybe for this round of pre-training I should be generating data on the fly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomizing Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nGenerating {num_samples} samples...\")\n",
    "Phi_samples = np.zeros((num_samples, Phi_dim, Phi_dim))\n",
    "phase_samples = np.zeros((num_samples, num_pix))\n",
    "fluo = Fluorescence1D(kmax=3, num_pix=num_pix, num_atoms=4)\n",
    "for i in tqdm(range(num_samples)):\n",
    "    fluo.num_atoms = np.random.randint(3, 20)\n",
    "    fluo.randomize_coords()\n",
    "    phase_samples[i, :] = fluo.coh_phase\n",
    "    _, Phi_samples[i, :, :] = fluo.cosPhi_from_phase() # returned value here is absPhi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean\", np.mean(Phi_samples))\n",
    "print(\"StdDev\", np.std(Phi_samples))\n",
    "print(\"RMS\", np.mean(4*Phi_samples**2))\n",
    "\n",
    "print(\"Mean\", np.mean(phase_samples))\n",
    "print(\"StdDev\", np.std(phase_samples))\n",
    "print(\"RMS\", np.mean(4*phase_samples**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is slower, because we are doing the same computation for the random phases above but adding a process that computes particular phases. If we wanted to generate inputs on-the-fly to save memory, we could just compute a bunch of these \"special\" phases and perform the last (fast) step to compute Phi in the DataLoader.\n",
    "\n",
    "Additionally, we could probably make randomize_coords a little bit more efficient and check cProfile results. Probably not a lot to gain though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing $g^{(3)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shots = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluo = Fluorescence1D(kmax=3, num_pix=num_pix, num_atoms=4)\n",
    "for i in tqdm(range(num_samples)):\n",
    "    fluo.num_atoms = np.random.randint(3, 20)\n",
    "    fluo.randomize_coords()\n",
    "    g3 = fluo.marginalize_g3(num_shots=num_shots)\n",
    "    # We only need a small slice of this, can we avoid generating the whole 2*num_pix by 2*num_pix array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are memory limited in how many g3 we can generate (if we have to pass through the 3D/6D array) or store (large datasets going as detector area squared), how efficient is it to generate this final round of fine-tuning data on-the-fly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$g^{(3)}$ Discretization Errors"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
